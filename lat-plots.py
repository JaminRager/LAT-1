#!/usr/bin/env python3
"""
===================== lat-plots.py ======================
A semi-official place to put plots of interest, primarily
using the "final" LAT cut files generated by lat-expo.py
=================== C. Wiseman (USC) ===================
"""
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('./pltReports.mplstyle')
from matplotlib.colors import LogNorm

import dsi
bkg = dsi.BkgInfo()
det = dsi.DetInfo()
cal = dsi.CalInfo()
import waveLibs as wl
import tinydb as db

def main():

    # spec()
    # spec_vs_cpd()
    # thresh_cut_cal()
    # ds3_det_eff()
    # hi_mult_cal_spec()
    # m2s238_sum_peak()
    # m2s238_hit_spec()
    # save_slowness_data()
    # slowness_vs_energy()
    # fitSlo_stability()
    # fitSlo_distribution()
    # fitSlo_det_efficiencies()
    fitSlo_tot_efficiencies()
    # fitSlo_exposure_weighted_eff()
    # get_ext_pulser_data()
    # plot_ext_pulser()


def spec():
    from ROOT import TFile, TChain, TTree

    dsList = [0,1,2,3,4,"5A","5B","5C"]

    tt = TChain("skimTree")
    enrExp, natExp = 0, 0
    for ds in dsList:
        inFile = "%s/bkg/cut/final/final_DS%s.root" % (dsi.dataDir, ds)
        tf = TFile(inFile)
        enrExp += float(tf.Get("enrExp (kg-d)").GetTitle())
        natExp += float(tf.Get("natExp (kg-d)").GetTitle())
        tf.Close()
        tt.Add(inFile)

    print("enrExp %.2f  natExp %.2f, ds" % (enrExp/365.25, natExp/365.25),dsList)

    fig = plt.figure(figsize=(8,7))
    p0 = plt.subplot(211)
    p1 = plt.subplot(212)
    xLo, xHi, xpb = 0, 20, 0.1

    # natural
    tCut = "!isEnr"
    n = tt.Draw("trapENFCal",tCut,"goff")
    hitE = tt.GetV1()
    hitE = [hitE[i] for i in range(n)]
    x, h1 = wl.GetHisto(hitE, xLo, xHi, xpb, shift=False)
    h1 = np.divide(h1, natExp*xpb) # scale by exposure and binning
    p0.plot(x, h1, 'b', ls='steps', lw=2, label="Natural")
    # p0.set_xlabel("Energy (keV)", ha='right', x=1)
    p0.set_ylabel("Counts/keV-kg-d", ha='right', y=1)
    p0.legend(loc=1)

    # enriched
    tCut = "isEnr"
    n = tt.Draw("trapENFCal",tCut,"goff")
    hitE = tt.GetV1()
    hitE = [hitE[i] for i in range(n)]
    x, h1 = wl.GetHisto(hitE, xLo, xHi, xpb, shift=False)
    h1 = np.divide(h1, enrExp*xpb) # scale by exposure and binning
    p1.plot(x, h1, 'b', ls='steps', lw=2, label="Enriched")
    p1.set_xlabel("Energy (keV)", ha='right', x=1)
    # p1.set_ylabel("Counts/keV-kg-d", ha='right', y=1)
    p1.legend(loc=1)

    plt.tight_layout()
    plt.show()


def spec_vs_cpd():
    from ROOT import TFile, TChain, TTree

    dsList = [0,1,2,3,4,"5A","5B","5C"]

    tt = TChain("skimTree")
    enrExp, natExp = 0, 0
    for ds in dsList:
        inFile = "%s/bkg/cut/final/final_DS%s.root" % (dsi.dataDir, ds)
        tf = TFile(inFile)
        enrExp += float(tf.Get("enrExp (kg-d)").GetTitle())
        natExp += float(tf.Get("natExp (kg-d)").GetTitle())
        tf.Close()
        tt.Add(inFile)
    print("enrExp %.2f  natExp %.2f, ds" % (enrExp/365.25, natExp/365.25),dsList)

    # the channel map changes across datasets, so we have to plot by CPD

    cpdList = []
    for ds in dsList:
        dsTmp = int(ds[0]) if isinstance(ds,str) else ds
        chTmp = det.getGoodChanList(dsTmp)
        for ch in chTmp:
            cpdList.append(int(det.getChanCPD(dsTmp,ch)))
    cpdList = sorted(list(set(cpdList)))

    enrList = [cpd for cpd in cpdList if det.allDetIDs[str(cpd)] > 100000]
    cpdEnrMap = {enrList[i]:i for i in range(len(enrList))}
    # enrLabels = enrList

    natList = [cpd for cpd in cpdList if det.allDetIDs[str(cpd)] < 100000]
    cpdNatMap = {natList[i]:i for i in range(len(natList))}
    # natLabels =


    fig = plt.figure(figsize=(8,7))
    p0 = plt.subplot(211)
    p1 = plt.subplot(212)
    xLo, xHi, xpb = 0, 20, 0.2

    # natural
    tCut = "!isEnr"
    yLo, yHi = 0, len(natList)
    nbx, nby = int((xHi-xLo)/xpb), len(natList)

    n = tt.Draw("trapENFCal:C:P:D",tCut,"goff")
    hitE, hitC, hitP, hitD = tt.GetV1(), tt.GetV2(), tt.GetV3(), tt.GetV4()
    hitE = [hitE[i] for i in range(n)]
    hitCPD = [cpdNatMap[ int("%d%d%d" % (hitC[i],hitP[i],hitD[i])) ] for i in range(n)]

    hNat,_,_,im0 = p0.hist2d(hitE, hitCPD, bins=[nbx, nby], range=[[xLo,xHi],[yLo,yHi]], cmap='jet')
    # p0.set_xlabel("Energy (keV)", ha='right', x=1.)
    p0.set_xticks(np.arange(xLo, xHi+1, 1.0))
    p0.set_ylabel("CPD, Natural", ha='right', y=1.)
    p0.set_yticks(np.arange(0, len(natList))+0.5)
    p0.set_yticklabels(natList, fontsize=8)

    # enriched
    tCut = "isEnr"
    yLo, yHi = 0, len(enrList)
    nbx, nby = int((xHi-xLo)/xpb), len(enrList)

    n = tt.Draw("trapENFCal:C:P:D",tCut,"goff")
    hitE, hitC, hitP, hitD = tt.GetV1(), tt.GetV2(), tt.GetV3(), tt.GetV4()
    hitE = [hitE[i] for i in range(n)]
    hitCPD = [ cpdEnrMap[int("%d%d%d" % (hitC[i],hitP[i],hitD[i])) ] for i in range(n)]

    hEnr,_,_,im1 = p1.hist2d(hitE, hitCPD, bins=[nbx, nby], range=[[xLo,xHi],[yLo,yHi]], cmap='jet')
    p1.set_xlabel("Energy (keV)", ha='right', x=1.)
    p1.set_xticks(np.arange(xLo, xHi+1, 1.0))
    p1.set_ylabel("CPD, Enriched", ha='right', y=1.)
    p1.set_yticks(np.arange(0, len(enrList))+0.5)
    p1.set_yticklabels(enrList, fontsize=8)

    cb0 = fig.colorbar(im0, ax=p0)
    cb1 = fig.colorbar(im1, ax=p1)
    # cb0.set_label('cts', ha='right', rotation=270, labelpad=20)


    plt.tight_layout()
    # plt.show()
    plt.savefig("./plots/lat-spec-vs-cpd.pdf")

    # ========= get detector counts =========

    eLo, eHi = 10, 11
    bLo, bHi = int(eLo/xpb), int(eHi/xpb)

    print("Natural Counts, %d-%d keV" % (eLo, eHi))
    for cpd in natList:
        col = cpdNatMap[cpd]
        print(cpd, int(np.sum(hNat[bLo:bHi,col])))

    print("Enriched Counts, %d-%d keV" % (eLo, eHi))
    for cpd in enrList:
        col = cpdEnrMap[cpd]
        print(cpd, int(np.sum(hEnr[bLo:bHi,col])))


def thresh_cut_cal():
    """ Adapted from LAT/sandbox/mult2.py, and dependent on input:
    "./data/mult2-dtVals-ene.npz"
    """
    import tinydb as db
    dsNum, bkgIdx = 5, 83
    calDB = db.TinyDB('./calDB.json')
    pars = db.Query()
    thD = dsi.getDBRecord("thresh_ds%d_bkgidx%d" % (dsNum, bkgIdx), False, calDB, pars)
    det = dsi.DetInfo()

    f = np.load("./data/mult2-dtVals-ene.npz")
    dtVals = f['arr_0'].item()
    mH = 1
    n = len(dtVals[mH])

    # plot 1: all hits under 10 keV
    # chan = [dtVals[mH][i][1][0] for i in range(n) if dtVals[mH][i][2][0]<10]
    # hitE = [dtVals[mH][i][2][0] for i in range(n) if dtVals[mH][i][2][0]<10]
    chan = [dtVals[mH][i][1][0] for i in range(n) if dtVals[mH][i][1][0] not in [598,1172] and dtVals[mH][i][2][0]<10]
    hitE = [dtVals[mH][i][2][0] for i in range(n) if dtVals[mH][i][1][0] not in [598,1172] and dtVals[mH][i][2][0]<10]

    # plot 2: only take hits above the detector threshold.
    n = len(hitE)
    chanTh, hitETh = [], []
    for i in range(n):
        if chan[i] in thD.keys() and hitE[i] > thD[chan[i]][0] + 3*thD[chan[i]][1]:
            chanTh.append(chan[i])
            hitETh.append(hitE[i])

    # make the figure

    f = plt.figure(figsize=(10,6))
    p1 = plt.subplot(121)
    p2 = plt.subplot(122)

    chList = list(sorted(set(chan)))

    cpd = {ch : int(det.getChanCPD(dsNum, ch)) for ch in chList}
    cpdList = sorted([int(det.getChanCPD(dsNum, ch)) for ch in chList])
    cpdIdx = {cpdList[i]:i for i in range(len(cpdList))}

    cpdData = [cpdIdx[cpd[ch]] for ch in chan]
    cpdDataTh = [cpdIdx[cpd[ch]] for ch in chanTh]

    xLo, xHi, xpb = 0.5, 5., 0.1
    yLo, yHi = 0, len(chList)
    nbx, nby = int((xHi-xLo)/xpb), len(chList)



    h1,xedg1,yedg1 = np.histogram2d(hitE, cpdData, bins=[nbx,nby], range=[[xLo,xHi],[yLo,yHi]])
    h2,xedg2,yedg2 = np.histogram2d(hitETh, cpdDataTh, bins=[nbx,nby], range=[[xLo,xHi],[yLo,yHi]])
    h1, h2 = h1.T, h2.T

    hMin, hMax = np.amin(h1), np.amax(h2)
    hMin, hMax = 2, hMax*1.3
    h1[h1 < 0.1] = -1
    h2[h2 < 0.1] = -1

    im1 = p1.imshow(h1,cmap='jet',vmin=hMin,vmax=hMax, aspect='auto')#,norm=LogNorm())

    xticklabels = ["%.1f" % x for x in np.arange(-0.5, 5.5, 1.)]

    yticks = np.arange(0, len(cpdList))

    p1.set_xlabel("Energy (keV)", ha='right', x=1.)
    # p1.set_xticks(xticks)
    p1.set_xticklabels(xticklabels)
    p1.set_ylabel("CPD", ha='right', y=1.)
    p1.set_yticks(yticks)
    p1.set_yticklabels(cpdList, fontsize=12)
    cb1 = f.colorbar(im1, ax=p1)#, fraction=0.037, pad=0.04)
    # cb1.set_label('Counts', ha='right', rotation=270, labelpad=20)

    im2 = p2.imshow(h2,cmap='jet',vmin=hMin,vmax=hMax, aspect='auto')#,norm=LogNorm())
    p2.set_xlabel("Energy (keV)", ha='right', x=1.)
    # p2.set_xticks(xticks)
    p2.set_xticklabels(xticklabels)
    p2.set_ylabel("CPD", ha='right', y=1.)
    p2.set_yticks(yticks)
    p2.set_yticklabels(cpdList, fontsize=12)
    cb2 = f.colorbar(im2, ax=p2)#, fraction=0.037, pad=0.04)
    # cb2.set_label('Counts', ha='right', rotation=270, labelpad=20)

    plt.tight_layout()

    # plt.show()
    plt.savefig("./plots/lat-dtm1-thresh.pdf")


def ds3_det_eff():
    """ Adapted from lat-expo.py::getEfficiency.
    Plots the combined trigger efficiency from each detector in DS3 separately.
    Also plots the slowness efficiency separately
    """
    import tinydb as db
    import lat3
    from ROOT import TFile, TTree
    import matplotlib.pyplot as plt
    plt.style.use('./pltReports.mplstyle')

    calDB = db.TinyDB('%s/calDB-v2.json' % (dsi.latSWDir))
    pars = db.Query()
    enrExc, natExc, _, _ = lat3.getOutliers(verbose=False, usePass2=False)

    mode = "trig"  # trigger efficiency only
    # mode = "all"   # does all PS

    # dsList = [0,1,2,3,4,"5A","5B","5C"]
    dsList = [3]

    # efficiency output
    xLo, xHi = 0, 30
    xEff = np.arange(xLo, xHi, 0.01)
    totEnrEff = {ds:np.zeros(len(xEff)) for ds in dsList}
    totNatEff = {ds:np.zeros(len(xEff)) for ds in dsList}
    detEff = {ds:{} for ds in dsList}
    for ds in dsList:
        detEff[ds] = {cpd:np.zeros(len(xEff)) for cpd in det.allDets}

    # recalculate these, make sure they match getExposure
    enrExp = {ds:0 for ds in dsList}
    natExp = {ds:0 for ds in dsList}

    # 1. loop over datasets
    for ds in dsList:

        # set DS stuff
        dsNum = int(ds[0]) if isinstance(ds,str) else ds
        nBkg = bkg.dsMap()[dsNum]
        bLo, bHi = 0, nBkg
        if ds=="5A": bLo, bHi = 0, 79
        if ds=="5B": bLo, bHi = 80, 112
        if ds=="5C": bLo, bHi = 113, 121
        bkgRanges = bkg.getRanges(ds)

        # get psa cut runs and detector fitSlo efficiencies
        f = np.load('./data/lat-psaRunCut-ds%s.npz' % ds)
        psaRuns = f['arr_0'].item() # {ch: [runLo1, runHi1, runLo2, runHi2, ...]}
        fsD = dsi.getDBRecord("fitSlo_cpd_eff", False, calDB, pars)

        # get burst cut
        dsTmp = ds
        if ds=="5A": dsTmp=50
        if ds=="5B": dsTmp=51
        if ds=="5C": dsTmp=52
        iE = np.where(enrExc[:,0]==dsTmp)
        iN = np.where(natExc[:,0]==dsTmp)
        skipList = np.vstack((enrExc[iE], natExc[iN]))
        # print(skipList)

        # load ds_livetime output
        tl = TFile("./data/ds_%s_livetime.root" % str(ds))
        lt = tl.Get("dsTree")

        # 2. loop over modules
        mods = [1]
        if dsNum == 4: mods = [2]
        if dsNum == 5: mods = [1,2]
        for mod in mods:

            calKey = "ds%d_m%d" % (dsNum, mod)
            if ds == "5C": calKey = "ds5c"
            if calKey not in cal.GetKeys(dsNum):
                print("Error: Unknown cal key:",calKey)
                return

            print("Scanning DS-%s, m%d ..." % (ds, mod))

            chList = det.getGoodChanList(dsNum, mod)

            # save total efficiency for each channel in this DS
            totEff = {ch:np.zeros(len(xEff)) for ch in chList}
            trigEff = {ch:np.zeros(len(xEff)) for ch in chList}
            fSloEff = {ch:np.zeros(len(xEff)) for ch in chList}

            # 3. loop over bkgIdx
            for i, bIdx in enumerate(bkgRanges):


                # load bkg (trigger) and cal (PSA) cut coverage
                _,_, bkgCov, calCov = dsi.GetDBCuts(ds,bIdx,mod,"fr",calDB,pars,False)

                rLo, rHi = bkgRanges[bIdx][0], bkgRanges[bIdx][-1]

                # get psa cut runs
                psaCutRuns = {ch:[] for ch in chList}
                for ch in chList:
                    if len(psaRuns[ch]) > 0:
                        for i in range(0,len(psaRuns[ch]),2):
                            psaCutRuns[ch].extend([r for r in range(psaRuns[ch][i],psaRuns[ch][i+1]+1) if rLo <= r <= rHi])

                # get burst cut runs
                burstCutRuns = {ch:False for ch in chList}
                for ch in chList:
                    cpd = det.getChanCPD(dsNum,ch)
                    iSkip = np.where((skipList == (dsTmp, int(cpd), bIdx)).all(axis=1))
                    if len(iSkip[0]) > 0:
                        burstCutRuns[ch] = True

                # 4. loop over sub-bIdx
                subRanges = bkg.GetSubRanges(ds, bIdx)
                if len(subRanges) == 0: subRanges.append((rLo, rHi))
                for sbIdx, (subLo, subHi) in enumerate(subRanges):

                    # load trigger efficiencies
                    key = "thresh_ds%d_bkg%d_sub%d" % (dsNum, bIdx, sbIdx)
                    thD = dsi.getDBRecord(key, False, calDB, pars)

                    # 5. loop over cIdx's in this sub-bIdx
                    cIdxLo, cIdxHi = cal.GetCalIdx(calKey, subLo), cal.GetCalIdx(calKey, subHi)
                    for i, cIdx in enumerate(range(cIdxLo, cIdxHi+1)):

                        # get the run coverage of this sub-sub-bIdx
                        if cIdxLo==cIdxHi:
                            covLo, covHi = subLo, subHi
                        else:
                            runList = bkg.getRunList(ds, bIdx)
                            subList = [r for r in runList if subLo <= r <= subHi and cal.GetCalIdx(calKey,r) == cIdx]
                            if len(subList)==0: continue
                            covLo, covHi = subList[0], subList[-1]

                        # calculate exposure for this sub-sub-bIdx
                        subExpo = {ch:0 for ch in chList}
                        n = lt.Draw("run:channel:livetime","run>=%d && run<=%d" % (covLo, covHi), 'goff')
                        ltRun, ltChan, ltLive = lt.GetV1(), lt.GetV2(), lt.GetV3()
                        for j in range(n):
                            ch = ltChan[j]
                            detID = det.getDetIDChan(dsNum,ch)
                            aMass = det.allActiveMasses[detID]
                            expo = ltLive[j]*aMass/86400/1000

                            # since we're splitting by module, ignore channels in the other module
                            # print(ds, mod, int(cpd[0]))
                            # exit()

                            if ch < 1000 and mod!=1: continue
                            if ch > 1000 and mod!=2: continue

                            if ltRun[j] in psaCutRuns[ch]:
                                continue
                            if burstCutRuns[ltChan[j]] is True:
                                continue
                            subExpo[ch] += expo

                            if detID > 100000:
                                enrExp[ds] += expo
                            else:
                                natExp[ds] += expo

                        # 6. loop over channels
                        for ch in chList:

                            goodThr = True if bkgCov[ch][sbIdx] else False
                            goodSlo = True if calCov[ch][0][i+1] else False
                            goodRise = True if calCov[ch][1][i+1] else False
                            if not (goodThr and goodSlo and goodRise):
                                continue

                            # finally, get trigger, fitSlo, and riseNoise efficiencies and scale by exposure

                            # trigger
                            mu, sig, isGood = thD[ch]
                            if isGood != 0:
                                print("error, bad threshold, ch",ch)
                                exit(1)
                            effThresh = mu + 3*sig
                            idx = np.where(xEff >= effThresh)
                            nPad = len(xEff) - len(xEff[idx])
                            tEff = wl.erFunc(xEff[idx],mu,sig,1)
                            tEff = np.pad(tEff, (nPad,0), 'constant')
                            tEff = np.multiply(tEff, subExpo[ch])

                            trigEff[ch] += tEff

                            # fitSlo & riseNoise
                            cpd = int(det.getChanCPD(dsNum,ch))
                            c, loc, scale, amp = fsD[cpd][3], fsD[cpd][4], fsD[cpd][5], fsD[cpd][2]
                            fEff = wl.weibull(xEff,c,loc,scale,amp)

                            riseEff = 0.995 # riseNoise is defined to be 99.5% efficient, no energy dependence
                            fEff = np.multiply(fEff, riseEff)

                            fSloEff[ch] += fEff

                            # total efficiency
                            if mode == "trig":
                                totEff[ch] += tEff
                            elif mode == "all":
                                totEff[ch] += np.multiply(tEff, fEff) # this is what we want
                            else:
                                print("Unknown mode! exiting ...")
                                exit()

            # plot individual efficiencies for a data set
            cmap = plt.cm.get_cmap('jet',len(chList)+1)
            cpdList = sorted([det.getChanCPD(dsNum,ch) for ch in chList])
            for iD, cpd in enumerate(cpdList):
                ch = det.getCPDChan(dsNum, str(cpd))
                if det.allDetIDs[str(cpd)] < 100000: continue
                if np.all(trigEff[ch]==0): continue

                idx = np.where(xEff < 2)
                print(cpd, np.sum(trigEff[ch][idx]))

                # plot 1 - trigger efficiency only
                # plt.plot(xEff, trigEff[ch], '-', c=cmap(iD), label="C%sP%sD%s" % (cpd[0],cpd[1],cpd[2])) # 1

                # plot 2 - slowness efficiency only
                # plt.plot(xEff, fSloEff[ch], '-', c=cmap(iD), label="C%sP%sD%s" % (cpd[0],cpd[1],cpd[2])) # 2

                # plot 2a - normalized efficiency
                plt.plot(xEff, fSloEff[ch]/np.amax(fSloEff[ch]), '-', c=cmap(iD), label="C%sP%sD%s" % (cpd[0],cpd[1],cpd[2])) # 2

                # plot 3 - total efficiency
                # plt.plot(xEff, totEff[ch], '-')

            # plt.xlim(0.5,6) # trigger limit
            plt.xlim(0.5, 30) # slowness limit

            plt.xlabel("Energy (keV)", ha='right', x=1)
            # plt.ylabel("Enr. Exposure (kg-d)", ha='right', y=1)
            plt.ylabel("Acceptance", ha='right', y=1)
            plt.legend(loc=4, ncol=3, fontsize=14)
            plt.tight_layout()
            # plt.show()
            # plt.savefig("./plots/lat-trigEff-DS3.pdf")
            # plt.savefig("./plots/lat-sloEff-DS3.pdf")
            plt.savefig("./plots/lat-sloEff-DS3-acc.pdf")
            exit()

        #     for ch in chList:
        #         cpd = det.getChanCPD(dsNum,ch)
        #         detEff[ds][cpd] = totEff[ch]
        #         # print(ch, cpd, detEff[ds][cpd][500:520], totEff[ch][500:520])
        #
        #     # plt.plot(xEff,detEff[ds]['164'])
        #     # plt.show()
        #     # exit()
        #
        # # ========= Done w/ 5 layer loop.  whew! =======
        #
        # # get total enr/nat efficiency for this DS
        # for cpd in detEff[ds]:
        #
        #     if det.allDetIDs[cpd] > 100000:
        #         totEnrEff[ds] += detEff[ds][cpd]
        #     else:
        #         totNatEff[ds] += detEff[ds][cpd]


def hi_mult_cal_spec():
    """ Adapted from sandbox/mult4.py
    sumSpec : {mHT: histos}
    hitData : [mHT, sumET, dt[mHT]]
    hitList : [hitE, chan, fSlo, rise, dtpc]  (same length as hitData)
    """
    # f1 = np.load("./data/mult4-sumE.npz")
    # f2 = np.load("./data/mult4-hitE.npz")
    f1 = np.load("./data/mult4-sumE-histats.npz")
    f2 = np.load("./data/mult4-hitE-histats.npz")
    runTime, x, sumSpec = f1['arr_0'], f1['arr_1'], f1['arr_2'].item()
    hitSpec, xHit, hitSpecLo = f1['arr_3'].item(), f1['arr_4'], f1['arr_5'].item()
    hitList, hitData, eCut = f2['arr_1'], f2['arr_2'], f2['arr_3']

    xLo, xHi, xpb = 0, 4000, 1

    # counts & rates for each multiplicity (use mHT)
    nHits = [sum(sumSpec[i]) for i in range(7)]
    nErr = [np.sqrt(nHits[i]) for i in range(7)]
    nPct = [100 / nErr[i] if nHits[i] > 0 else 0 for i in range(7)]
    rate = [nHits[i] / runTime for i in range(7)]
    rErr = [nErr[i] / runTime for i in range(7)]

    # sum spectrum
    fig = plt.figure()
    xLo, xHi, xpb = 0, 4000, 2
    cols = [0,'r','b','m','g','c','k']
    for mHT in range(1,5):
        pLabel = r'mHT=%d %.2f $\pm$ %.3f Hz' % (mHT,rate[mHT],rErr[mHT])
        plt.semilogy(x, sumSpec[mHT], ls='steps', lw=1.5, c=cols[mHT],label=pLabel)
    plt.xlabel("sumET (keV)", ha='right', x=1.)
    plt.ylabel("Counts / %.1f keV" % (xpb), ha='right', y=1.)
    plt.legend(fontsize=14)
    plt.tight_layout()
    plt.savefig("./plots/lat-sumSpec.pdf")

    # sum spectrum, events w/ 1 or more hit under 'eCut' keV
    plt.cla()
    n = len(hitList)
    for mHT in range(2,5):
        evts = [hitData[i][1] for i in range(n) if hitData[i][0] == mHT]
        plt.semilogy(*wl.GetHisto(evts,xLo,xHi,xpb), ls='steps', lw=1.5, c=cols[mHT], label='mHT=%d, eCut:%.0f keV' % (mHT, eCut))
    plt.xlabel("sumE (keV)", ha='right', x=1.)
    plt.ylabel("Counts / %.1f keV" % (xpb), ha='right', y=1.)
    plt.legend(fontsize=14)
    plt.tight_layout()
    plt.savefig("./plots/lat-selectSpec.pdf")

    # hit spectrum
    plt.cla()
    for mHT in range(1,5):
        plt.semilogy(x, hitSpec[mHT], ls='steps', lw=1.5, c=cols[mHT], label='mHT=%d' % mHT)
    plt.xlabel("hitE (keV)", ha='right', x=1.)
    plt.ylabel("Counts / %.1f keV" % (xpb), ha='right', y=1.)
    plt.legend(fontsize=14)
    plt.tight_layout()
    plt.savefig("./plots/lat-hitSpec.pdf")

    # hit spectrum, under 20 kev
    plt.cla()
    for mHT in range(1,5):
        plt.semilogy(xHit, hitSpecLo[mHT], ls='steps', lw=1.5, c=cols[mHT], label='mHT=%d' % mHT)
    plt.xlabel("hitE (keV)", ha='right', x=1.)
    plt.ylabel("Counts / %.1f keV" % (xpb), ha='right', y=1.)
    plt.legend(loc=1, fontsize=14)
    plt.tight_layout()
    plt.savefig("./plots/lat-hitSpecLow.pdf")


def m2s238_sum_peak():

    # f = np.load("./data/mult2-peaks.npz")
    f = np.load("./data/mult2-peaks-histats.npz") # full cal run
    runTime, pks, pkHist = f['arr_0'], f['arr_1'], f['arr_2'].item()

    # note: to access x and y histogram values:
    # x, y = pkHist[mH][iPk][0], pkHist[mH][iPk][1]

    def roughSigma(ene):
        """ from gpxFitter, just used to set initial guesses """
        p0, p1, p2 = 0.2, 0.02, 0.0003
        return np.sqrt(p0**2. + p1**2. * ene + p2**2. * ene**2.)


    def gaus(x, b, a, mu, sig):
        """ gaussian + flat bg """
        return b + a * np.exp(-(x-mu)**2. / (2. * sig**2.))

    from scipy.optimize import curve_fit

    pkE, mH, iPk = 238, 2, 0

    x, y = pkHist[mH][iPk][0], pkHist[mH][iPk][1]

    # xpb = 0.1
    # x = x + xpb/2.

    fig = plt.figure()

    plt.plot(x, y, c='b', ls='steps-mid', label="Calib, mHT==%d" % (mH))

    p0 = (np.mean(y[:5]), max(y), pkE, roughSigma(pkE))
    popt,_ = curve_fit(gaus, x, y, p0=p0)

    bpx = x[1] - x[0]
    bgRate = popt[0] * bpx
    mu, sig = popt[2], popt[3]
    idx = np.where((x > mu-3*sig) & (x < mu+3*sig))
    totCts = np.sum(y[idx])
    bgCts = bgRate * len(y[idx])
    pkCts = totCts - bgCts
    pbr = pkCts / bgCts
    print("%d  %.2f  %.2f  %.2f  %.2f  %d  %d  %d  P/B: %.2f" % (pkE, bpx, bgRate, mu, sig, totCts, bgCts, pkCts, pbr))

    sumLo, sumHi = mu-3*sig, mu+3*sig
    print("sumLo, sumHi = %.2f, %.2f" % (mu-3*sig, mu+3*sig))

    xVals = np.arange(236, 240, 0.01)

    plt.plot(xVals, gaus(xVals, *popt), 'r-', lw=4, alpha=0.7, label="%s = %.2f, 3%s = %.2f" % (r'$\mu$', popt[2], r'$\sigma$', 3*popt[3]))

    # 'fit.  mu %.2f  sig %.2f\nP/B %.2f' % (popt[2], popt[3], pbr))
    plt.axvline(sumLo, lw=3, alpha=0.7, c='g', label="%.2f - %.2f keV" % (sumLo, sumHi))
    plt.axvline(sumHi, lw=3, alpha=0.7, c='g')
    plt.plot(np.nan, np.nan, c='w', label="P/B = %.1f" % pbr)

    # plt.title("Peak-to-bkg ratio: %.3f" % pbr)
    plt.xlabel("sumET (keV)", ha='right', x=1.)
    plt.ylabel("Counts", ha='right', y=1.)
    plt.legend(loc=1)
    plt.xlim(236,242)
    plt.tight_layout()
    # plt.show()
    plt.savefig("./plots/lat-m%d-pk%d.pdf" % (mH,iPk))


def m2s238_hit_spec():
    """
    Adapted from sandbox/mult4.py::plotSpecTest.
    sumSpec : {mHT: histos}
    hitData : [mHT, sumET, dt[mHT]]
    hitList : [hitE, chan, fSlo]  (same length as hitData)
    """
    f1 = np.load("./data/mult4-sumE-histats.npz")
    f2 = np.load("./data/mult4-hitE-histats.npz")
    runTime, x, sumSpec = f1['arr_0'], f1['arr_1'], f1['arr_2'].item()
    hitSpec, xHit, hitSpecLo = f1['arr_3'].item(), f1['arr_4'], f1['arr_5'].item()
    hitList, hitData, eCut = f2['arr_1'], f2['arr_2'], f2['arr_3']

    # fitSlo results from tuneFitSlo.
    fsVals = {
        584: 102.5, 592: 75.5, 608: 73.5, 610: 76.5, 614: 94.5, 624: 69.5,
        626: 81.5, 628: 102.5, 632: 81.5, 640: 73.5, 648: 74.5, 658: 75.5,
        660: 127.5, 662: 84.5, 672: 80.5, 678: 82.5, 680: 86.5, 688: 77.5,
        690: 80.5, 694: 80.5
        }
    chList = fsVals.keys()

    mHT = 2

    hitE, chan, fSlo = [], [], []
    for i in range(len(hitData)):
        if hitData[i][0]==mHT and 237.28 < hitData[i][1] < 239.46:
        # if hitData[i][0]==mHT and 235 < hitData[i][1] < 240:
            hitE.extend(hitList[i][0])
            chan.extend(hitList[i][1])
            fSlo.extend(hitList[i][2])
    n = len(hitE)
    hitE = [hitE[i] for i in range(n) if chan[i] in fsVals.keys()]
    fSloShift = [fSlo[i]-fsVals[chan[i]] for i in range(n) if chan[i] in chList]

    hitESlow = [hitE[i] for i in range(len(hitE)) if fSloShift[i] > 30]
    hitEFast = [hitE[i] for i in range(len(hitE)) if fSloShift[i] < 30]

    xLo, xHi, xpb = 0, 250, 1
    x, hSlo = wl.GetHisto(hitESlow,xLo,xHi,xpb)
    x, hFast = wl.GetHisto(hitEFast,xLo,xHi,xpb)

    # load sim data
    # fs = np.load("./data/mult4-evtTrans.npz")
    # hits = fs['arr_0'].item()
    # evtTotal, evtBulk, evtTrans = hits[0], hits[1], hits[2]
    # eneTotal, eneBulk, eneTrans = hits[3], hits[4], hits[5]
    # x, hTotal = wl.GetHisto(evtTotal, xLo, xHi, xpb)
    # x, hBulk = wl.GetHisto(evtBulk, xLo, xHi, xpb)
    # x, hTrans = wl.GetHisto(evtTrans, xLo, xHi, xpb)
    # x, hETotal = wl.GetHisto(eneTotal, xLo, xHi, xpb)
    # x, hEBulk = wl.GetHisto(eneBulk, xLo, xHi, xpb)
    # x, hETrans = wl.GetHisto(eneTrans, xLo, xHi, xpb)

    f = plt.figure()

    # plt.plot(x, hEBulk/np.sum(hEBulk), ls='steps', c='g', lw=2., label='sim bulk')
    # plt.plot(x, hFast/np.sum(hFast), ls='steps', c='b', lw=2., label='data fast')
    plt.plot(x, hFast, ls='steps', c='b', label="m2s238 Hits")
    plt.xlabel("Energy (keV)", ha='right', x=1)
    plt.ylabel("Counts / %.1f keV" % xpb, ha='right', y=1)
    plt.axvline(123.3, c='g', lw=4, alpha=0.7, label=r"$E_C$: 123.3 keV")

    plt.ylim(ymax=np.amax(hFast)*1.3)
    plt.legend(loc=1)
    plt.tight_layout()

    # plt.show()
    plt.savefig("./plots/lat-238hits.pdf")


def save_slowness_data():
    """ Save the data for a plot of fitSlo vs energy, shifted and unshifted.
    Saving s/t I can use the thesis plot format on my mac.
    """
    from ROOT import TChain
    import tinydb as db

    ds, cIdx, calKey = 1, 1, "ds1_m1"

    # load the fitSlo values for this cIdx
    shiftVals = {}
    calDB = db.TinyDB('%s/calDB-v2.json' % (dsi.latSWDir))
    pars = db.Query()
    fsD = dsi.getDBRecord("fitSlo_%s_idx%d_m2s238" % (calKey, cIdx), False, calDB, pars)
    chList = det.getGoodChanList(ds)
    for ch in chList:
        if ch not in fsD.keys():
            print("Error, channel %d not found" % ch)
            exit()
        # "fitSlo_[calKey]_idx[ci]_m2s238" : {ch : [fsCut, fs200] for ch in chList}}
        # NOTE: fsCut is the 90% value, already shifted back for this calibration index
        #       fs200 is the mean fitSlo value for this channel.
        # print(ch, fsD[ch][0], fsD[ch][1])
        if fsD[ch] is not None and fsD[ch][0] > 0:
            shiftVals[ch] = fsD[ch][1]
    cutChanList = sorted(shiftVals.keys())
    # for ch in cutChanList:
        # print(ch, shiftVals[ch])

    # load the cal runs
    fList = []
    cRuns = cal.GetCalList(calKey, cIdx)
    for run in cRuns:
        latList = dsi.getSplitList("%s/latSkimDS%d_run%d*" % (dsi.calLatDir, ds, run), run)
        tmpList = [f for idx, f in sorted(latList.items())]
        fList.extend(tmpList)


    tt = TChain("skimTree")
    for f in fList: tt.Add(f)

    n = tt.Draw("trapENFCal:fitSlo:channel","","goff")
    hitE, fSlo, chan = tt.GetV1(), tt.GetV2(), tt.GetV3()
    hitE = [hitE[i] for i in range(n)]
    fSlo = [fSlo[i] for i in range(n)]
    chan = [chan[i] for i in range(n)]

    # unshifted values
    hitE1 = [hitE[i] for i in range(n) if chan[i] in cutChanList]
    fSlo1 = [fSlo[i] for i in range(n) if chan[i] in cutChanList]

    # shifted values
    hitE2 = hitE1
    fSlo2 = [fSlo[i] - shiftVals[chan[i]] for i in range(n) if chan[i] in cutChanList]

    np.savez("./data/lat-slowness.npz", hitE1, fSlo1, fSlo2)


def slowness_vs_energy():

    from matplotlib import colors
    myNorm = colors.PowerNorm(gamma=0.2)
    # myNorm = colors.PowerNorm(gamma=1)
    # myNorm = colors.LogNorm()

    f = np.load("./data/lat-slowness.npz")
    hitE1, fSlo1, fSlo2 = f['arr_0'], f['arr_1'], f['arr_2']

    fig = plt.figure(figsize=(9,5))
    p1 = plt.subplot(121)
    p2 = plt.subplot(122)

    xLo, xHi, xpb = 0, 250, 1
    nbx = int((xHi-xLo)/xpb)
    yLo, yHi, ypb = 0, 200, 1
    nby = int((yHi-yLo)/ypb)

    p1.hist2d(hitE1, fSlo1, bins=[nbx, nby], range=[[xLo,xHi],[yLo,yHi]], cmap='jet', norm=myNorm)
    p1.set_xlabel("Energy (keV)", ha='right', x=1)
    p1.set_ylabel("fitSlo", ha='right', y=1)
    p1.annotate('Unshifted', xy=(240, 270), xycoords='axes points', size=14, ha='right', va='center', bbox=dict(boxstyle='round', fc='w', alpha=0.75))

    yLo, yHi, ypb = -75, 125, 1
    nby = int((yHi-yLo)/ypb)

    p2.hist2d(hitE1, fSlo2, bins=[nbx, nby], range=[[xLo,xHi],[yLo,yHi]], cmap='jet', norm=myNorm)
    p2.set_xlabel("Energy (keV)", ha='right', x=1)
    p2.annotate('Shifted', xy=(240, 270), xycoords='axes points', size=14, ha='right', va='center', bbox=dict(boxstyle='round', fc='w', alpha=0.75))
    # p2.set_ylabel("fitSlo (shifted)", ha='right', y=1)

    plt.tight_layout()
    plt.show()
    # plt.savefig("./plots/lat-fitSlo-dist.pdf")


def fitSlo_stability():
    """ Adapted from LAT/sandbox/slo-cut.py::plotEff
    That function made seven plots:
    1. hit spectrum, all channels, 0-250
    2. bar plot, hits in all channels
    3. 2d hits vs channels, 0-20 keV
    4. typical fitSlo values
    5. m2s238 slowness
    5. difference between m2s238 and pk238 90pct cut values
    6. stability of fitSlo vs run number (calIdx)
    """
    import os

    # arrays to plot m2s238 data
    effHitE = []  # [hitE1, hitE2 , ...] (remove sub-list of input format)
    effChan = []  # [chan1, chan2 , ...]
    effSlo = []   # [fSlo1, fSlo2, ...]
    effRise = []  # [rise1, rise2, ...]
    effRun = []   # [run1, run1, ...]

    sloSpec = [] # array of fitSlo histo dicts (i should have used pandas probably)

    # load efficiency files
    fList = []
    for ds in [4]:
        # print("Loading DS-%d" % ds)
        for key in cal.GetKeys(ds):
            mod = -1
            if "m1" in key: mod = 1
            if "m2" in key: mod = 2
            for cIdx in range(cal.GetIdxs(key)):
                eFile = "%s/eff_%s_c%d.npz" % (dsi.effDir, key, cIdx)
                if os.path.isfile(eFile):
                    fList.append([ds,cIdx,mod,eFile])
                else:
                    print("File not found:",eFile)
                    continue
    for ds,ci,mod,ef in fList:
        # print(ds,ci,mod,ef)
        f = np.load(ef)
        evtIdx = f['arr_0']          # m2s238 event [[run,iE] , ...]
        evtSumET = f['arr_1']        # m2s238 event [sumET , ...]
        evtHitE = f['arr_2']         # m2s238 event [[hitE1, hitE2] , ...]
        evtChans = f['arr_3']        # m2s238 event [[chan1, chan2] , ...]
        thrCal = f['arr_4'].item()   # {ch : [run,thrM,thrS,thrK] for ch in goodList(ds)}
        thrFinal = f['arr_5'].item() # {ch : [thrAvg, thrDev] for ch in goodList(ds)}
        evtCtr = f['arr_6']          # num m2s238 evts
        totCtr = f['arr_7']          # num total evts
        runTime = f['arr_8']         # cal run time
        fSloSpec = f['arr_9'].item() # fitSlo histos (all hits) {ch:[h10, h200, h238] for ch in chList}
        fSloX = f['arr_10']          # xVals for fitSlo histos
        evtSlo = f['arr_11']         # m2s238 event [[fSlo1, fSlo2], ...]
        evtRise = f['arr_12']        # m2s238 event [[rise1, rise2], ...]

        sloSpec.append(fSloSpec)

        # remove the hit pair
        for i in range(len(evtHitE)):
            effHitE.extend(evtHitE[i])
            effChan.extend(evtChans[i])
            effSlo.extend(evtSlo[i])
            effRise.extend(evtRise[i])
            effRun.extend([evtIdx[i][0],evtIdx[i][0]])

    effHitE = np.asarray(effHitE)
    effChan = np.asarray(effChan)
    effSlo = np.asarray(effSlo)
    effRun = np.asarray(effRun)

    chList = det.getGoodChanList(ds)
    cpdList = sorted([det.getChanCPD(ds,ch) for ch in chList])

    # plot 6 -- stability of DS4

    fig = plt.figure()
    cmap = plt.cm.get_cmap('jet', len(chList)+1)

    for i, cpd in enumerate(cpdList):
        ch = det.getCPDChan(ds, cpd)
        type = "e" if det.allDetIDs[cpd] > 100000 else "n"
        # print(i, cpd, ch)
        plt.plot(np.nan, np.nan, ".-", c=cmap(i), label="C%sP%sD%s (%s)" % (cpd[0],cpd[1],cpd[2], type))

        fs200, x200, fsm2s238 = [], [], []
        for ci in range(len(sloSpec)):

            # only save the value if we have a nonzero number of counts
            spec = sloSpec[ci][ch][1]
            nCts = np.sum(spec)
            if nCts < 2: continue
            # print(ds,ch,ci,nCts)

            # get the width
            max, avg, std, pct, wid = wl.getHistInfo(fSloX, sloSpec[ci][ch][1])

            # TODO: smarter way to get the width
            # like a FWHM.  find the max, then find the point of 50% reduction on either side

            fs200.append(fSloX[np.argmax(sloSpec[ci][ch][1])])
            x200.append(ci)

            # get m2s238 events from this calIdx and find the typical value
            idx = np.where(effChan==ch)
            tmpS = effSlo[idx]
            tmpC = effChan[idx]
            tmpR = effRun[idx]
            thisFS = []
            for j in range(len(tmpR)):
                key = "ds%d_m1" % ds if ch < 1000 else "ds%d_m2" % ds
                if ci == cal.GetCalIdx(key,tmpR[j]):
                    thisFS.append(tmpS[j])
            nEff = len(thisFS)

            yLo, yHi, ypb = -50, 400, 1
            x, hSlo = wl.GetHisto(thisFS, yLo, yHi, ypb)
            maxEff = np.nan if len(thisFS)==0 else x[np.argmax(hSlo)]

            # NOTE: the diff is NEVER more than 1.
            # print("%d  %-3d  nTot %-8d  nEff %-5d  wid %-4.0f  fs200 %-4.0f  fsEff %-4.0f  diff %.0f" % (ch, ci, nCts, nEff, wid, fs200[-1], maxEff, fs200[-1]-maxEff))

            fsm2s238.append(maxEff)


        # plot the raw value (stability)
        plt.plot(x200, fs200, ".-", c=cmap(i))
        # plt.axhline(np.mean(fs200), c=cmap(i), linewidth=0.5, label="ch%d: %.2f")
        plt.ylim(0,150)

        # plot the difference from the average (deviation)
        # fAvg = np.mean(fs200)
        # fDev = [(f-fAvg) for f in fs200]
        # p2.plot(x200, fDev, ".", c=cmap(i), label="ch%d  fAvg %.0f" % (ch, fAvg))

        # plot the difference between the raw value and the m2s238 value
        # man, i shoulda just added the calIdx of the m2s238 hits

    plt.xlabel("DS4, calIdx", ha='right', x=1)
    plt.ylabel("fitSlo", ha='right', y=1)
    plt.xticks(np.arange(0,len(sloSpec),1))
    plt.legend(loc=3, ncol=3, fontsize=14)
    # if ds!=5: p1.legend(ncol=3)
    # else: p1.legend(ncol=6, fontsize=8)
    # p2.set_ylabel("fitSlo Deviation from avg", ha='right', y=1)
    plt.tight_layout()
    # plt.show()
    plt.savefig("./plots/lat-stability-ds%d.pdf" % (ds))


def fitSlo_distribution():
    """ Adapted from mult4.py::plotFitSloHist.
    hitData : [mHT, sumET, dt[mHT]]
    hitList : [hitE, chan, fSlo, rise, dtpc]  (same length as hitData)
    """
    # fitSlo results from tuneFitSlo.
    fsVals = {
        584: 102.5, 592: 75.5, 608: 73.5, 610: 76.5, 614: 94.5, 624: 69.5,
        626: 81.5, 628: 102.5, 632: 81.5, 640: 73.5, 648: 74.5, 658: 75.5,
        660: 127.5, 662: 84.5, 672: 80.5, 678: 82.5, 680: 86.5, 688: 77.5,
        690: 80.5, 694: 80.5
        }

    chList = list(fsVals.keys())

    # peak fit results from mult2.  could retune, but it shouldn't matter much
    mHT = 2
    sumPks = [
        (2,238,237.28,239.46), (2,583,581.26,584.46), (2,2615,2610.57,2618.01),
        (3,238,237.13,239.43), (3,583,581.04,584.36), (3,2615,2610.10,2617.92)
        ]

    # f1 = np.load("./data/mult4-hitE.npz")
    f1 = np.load("./data/mult4-hitE-histats.npz")
    runTime, hitList, hitData, eCut = f1['arr_0'], f1['arr_1'], f1['arr_2'], f1['arr_3']

    hitE, chan, fSlo = [], [], []
    for i in range(len(hitData)):
        if hitData[i][0]==mHT and 237.28 < hitData[i][1] < 239.46:
            hitE.extend(hitList[i][0])
            chan.extend(hitList[i][1])
            fSlo.extend(hitList[i][2])
    n = len(hitE)
    hitE = [hitE[i] for i in range(n) if chan[i] in fsVals.keys()]
    fSloShift = [fSlo[i]-fsVals[chan[i]] for i in range(n) if chan[i] in chList]
    print("peak evts:",n)

    cLo, cHi = 0, 230

    hitE2, chan2, fSlo2 = [], [], []
    for i in range(len(hitData)):
        if hitData[i][0]==mHT and cLo < hitData[i][1] < cHi:
            hitE2.extend(hitList[i][0])
            chan2.extend(hitList[i][1])
            fSlo2.extend(hitList[i][2])
    n = len(hitE2)
    hitE2 = [hitE2[i] for i in range(n) if chan2[i] in fsVals.keys()]
    fSloShift2 = [fSlo2[i]-fsVals[chan2[i]] for i in range(n) if chan2[i] in chList]
    print("cont evts:",n)

    fig = plt.figure()

    xLo, xHi, xpb = 0, 250, 1
    nbx = int((xHi-xLo)/xpb)
    yLo, yHi, ypb = -50, 400, 1
    nby = int((yHi-yLo)/ypb)

    # # ===== 1.  2d fitSlo vs energy, m2s238 hits, shifted. ======
    #
    # hitE2, chan2, fSlo2 = [], [], []
    # for i in range(len(hitData)):
    #     if hitData[i][0]==mHT and cLo < hitData[i][1] < cHi:
    #         hitE2.extend(hitList[i][0])
    #         chan2.extend(hitList[i][1])
    #         fSlo2.extend(hitList[i][2])
    # n = len(hitE2)
    # hitE2 = [hitE2[i] for i in range(n) if chan2[i] in fsVals.keys()]
    # fSloShift = [fSlo2[i]-fsVals[chan2[i]] for i in range(n) if chan2[i] in chList]
    # print("cont evts:",n)
    #
    # plt.hist2d(hitE2, fSloShift, bins=[nbx, nby], range=[[xLo,xHi],[yLo,yHi]], norm=LogNorm(), cmap='jet', label='m=2, hits 0-230 keV')
    # plt.colorbar()
    # plt.xlabel("Energy (keV)", ha='right', x=1.)
    # plt.ylabel("fitSlo", ha='right', y=1.)
    # plt.tight_layout()
    # plt.savefig("./plots/mult4-fitSlo-shift2-hist.png")


    # ===== 2.

    # cb.remove()
    plt.cla()
    xLo, xHi, xpb = -50, 300, 1

    x, y238 = wl.GetHisto(fSloShift,xLo,xHi,xpb)
    x, yCon = wl.GetHisto(fSloShift2,xLo,xHi,xpb)

    # integral238
    tot238 = np.sum(y238)
    int238, x238 = 0, 0
    for i in range(len(y238)):
        int238 += y238[i]
        if int238/tot238 > 0.90:
            x238 = x[i]
            break

    # integralCon
    totCon = np.sum(yCon)
    intCon, xCon = 0, 0
    for i in range(len(yCon)):
        intCon += yCon[i]
        if intCon/totCon > 0.95:
            xCon = x[i]
            break

    plt.semilogy(x, yCon/np.sum(yCon), 'r', ls='steps', label='All hits, %d-%d keV' % (cLo, cHi))
    plt.semilogy(x, y238/np.sum(y238), 'b', ls='steps', label='m2s238 Hits')

    # plt.axvline(x238, c='g', label='m2s238 90%, all dets')

    plt.xlabel("fitSlo (Shifted)", ha='right', x=1.)
    plt.ylabel("Counts (Normalized)", ha='right', y=1.)

    plt.legend(loc=1)
    plt.tight_layout()
    # plt.show()
    plt.savefig("./plots/lat-fitSlo-hist.pdf")


def fitSlo_det_efficiencies():
    """ Load the efficiency data from LAT2 directly for faster plotting.
    This is where we do the final efficiency fit, apparently.
    """
    from statsmodels.stats import proportion
    from scipy.optimize import curve_fit

    # must match lat2
    # pctTot = 90
    pctTot = 95
    xPassLo, xPassHi, xpbPass = 0, 50, 1      # "low energy" region

    print("Using pctTot ==",pctTot)

    # weibull fit constraints: energy, (c, loc, scale, amp)
    eFitHi = 30
    # fitBnd = ((0,-15,0,0),(np.inf,np.inf,np.inf,1.)) # this is the original
    fitBnd = ((1,-20,0,0.5),(np.inf,np.inf,np.inf, 0.99)) # eFitHi=30 and these works!

    # load efficiency data
    f = np.load('./data/lat2-eff-data-%d.npz' % pctTot)
    effData = f['arr_0'].item()

    fig = plt.figure(3) # efficiency plot
    p1 = plt.subplot2grid((3,1), (0,0), rowspan=2)
    p2 = plt.subplot2grid((3,1), (2,0), sharex=p1)

    print("CPD   amp     c       loc      scale   e1keV  nBin   maxR    chi2")
    detList = det.allDets
    for i, cpd in enumerate(detList):
    # for i, cpd in enumerate(['122', '114', '273', '133']): # these have convergence issues
    # for i, cpd in enumerate(['133']):

        if cpd not in effData.keys():
            # print(cpd)
            # print("%s & & & & & & & & & \\\\" % cpd)
            continue

        xEff, sloEff, ci_low, ci_upp = effData[cpd][0], effData[cpd][1], effData[cpd][2], effData[cpd][3]
        hPass, hFail, hTot, xELow = effData[cpd][4], effData[cpd][5], effData[cpd][6], effData[cpd][7]

        # get the average number of counts per bin under 10 kev, both passing and failing
        # nBin = np.sum(hTot[np.where(xELow < 10)])/(10/xpbPass)
        nBin = np.sum(hPass[np.where(xELow < 10)])/(10/xpbPass)

        # efficiency for low-E region (xPassLo, xPassHi)

        # start by only looking at points where we have >0 hits passing
        idxP = np.where(hPass > 0)
        sloEff = hPass[idxP] / hTot[idxP]
        xEff = xELow[idxP]

        # calculate confidence intervals for each point (error bars)
        ci_low, ci_upp = proportion.proportion_confint(hPass[idxP], hTot[idxP], alpha=0.1, method='beta')

        # limit the energy range
        idxE = np.where((xEff < xPassHi) & (xEff > 1))
        xEff, sloEff, ci_low, ci_upp = xEff[idxE], sloEff[idxE], ci_low[idxE], ci_upp[idxE]

        # ** this is essential, otherwise the blue dots show up on the right side of
        # where the bin center would be, and throw off the fit by half a bin width
        xEff -= xpbPass/2.

        # limit the fit energy range
        idxF = np.where(xEff <= eFitHi)

        # run the fit
        popt, pcov = curve_fit(wl.weibull, xEff[idxF], sloEff[idxF], bounds=fitBnd)

        # save pars and errors
        perr = np.sqrt(np.diag(pcov))
        c, loc, sc, amp = popt
        cE, locE, scE, ampE = perr
        eff1 = wl.weibull(1.,*popt)

        from scipy.stats import chisquare
        # "This test is invalid when the observed or expected frequencies in each category are too small. A typical rule is that all of the observed and expected frequencies should be at least 5."
        # wenqin: the bin errors are binomial.  see https://root.cern.ch/doc/master/classTEfficiency.html
        chi2, p = chisquare(sloEff, wl.weibull(xEff,*popt))

        # get residual
        hResidSig = []
        n = len(sloEff)
        for i in range(n):
            diff = wl.weibull(xEff[i], *popt) - sloEff[i]
            sig = ci_upp[i] if diff > 0 else ci_low[i]
            if sig==0:
                # print("zero at",xEff[i],"kev")
                hResidSig.append(0)
                continue
            hResidSig.append(diff/sig)
        hResidSig = np.asarray(hResidSig)

        # find abs. max of residual
        maxR = np.max(np.fabs(hResidSig))

        # print results
        # print("%s  %-4.3f  %-4.1f  %-7.2f  %-5.2f  %-3.2f  %d  %.3f  %.3f" % (cpd, amp, c, loc, sc, eff1, nBin, maxR, chi2))

        # print latexable results
        print("%s & %-4.3f & %-4.1f & %-7.2f & %-5.2f & %-3.2f & %-4d & %-5.3f & %-5.3f \\\\" % (cpd, amp, c, loc, sc, eff1, nBin, maxR, chi2))

        # print ugly one with errors
        # print("%s  a %.3f (%.3f)  c %.1f (%.1f)  loc %.2f (%.2f)  sc %.2f (%.2f)  eff1 %.2f  nBin %d" % (cpd, amp, ampE, c, cE, loc, locE, sc, scE, eff1, nBin))

        # === make the efficiency plot, with sigma residual ===

        # plot efficiency
        p1.cla()
        p1.plot(xEff, sloEff, '.b', ms=10., label='C%sP%sD%s, nBin %.1f' % (cpd[0],cpd[1],cpd[2],nBin))
        p1.errorbar(xEff, sloEff, yerr=[sloEff - ci_low, ci_upp - sloEff], color='k', linewidth=0.8, fmt='none')

        xFunc = np.arange(xPassLo, xPassHi, 0.1)
        p1.plot(xFunc, wl.weibull(xFunc, *popt), 'g-', label=r'Weibull CDF')
        p1.axvline(1.,color='b', lw=1., label='1.0 keV efficiency: %.2f' % wl.weibull(1.,*popt))

        p1.set_xlim(xPassLo, xPassHi)
        p1.set_ylim(0,1)
        # p1.set_xlabel("hitE (keV)", ha='right', x=1)
        p1.set_ylabel("Efficiency", ha='right', y=1)
        p1.yaxis.set_label_coords(-0.095, 1.)
        p1.legend(loc=4)

        # plot residual
        p2.cla()
        p2.plot(xEff, hResidSig, ".g")
        p2.annotate('Residual, Fit - Data', xy=(470, 80), xycoords='axes points', size=14, ha='right', va='center', bbox=dict(boxstyle='round', fc='w', alpha=0.75, edgecolor='gray'))
        p2.axvline(1.,color='b', lw=1.)

        p2.set_xlim(xPassLo, xPassHi)
        yLo = -0.4 if np.min(hResidSig) > -0.4 else np.min(hResidSig) * 1.1
        yHi = 0.4 if np.max(hResidSig) < 0.4 else np.max(hResidSig) * 1.1
        p2.set_ylim(yLo, yHi)

        p2.set_ylabel("Residual (Sigma)")
        p2.set_xlabel("Energy (keV)", ha='right', x=1)
        p2.set_xticks(np.arange(0,51,5))

        plt.tight_layout()
        fig.subplots_adjust(hspace=0.01)
        plt.setp(p1.get_xticklabels(), visible=False)

        # plt.show()
        # exit()
        plt.savefig("./plots/lat2-eff%d-%s.pdf" % (pctTot,cpd))


def fitSlo_tot_efficiencies():
    """ Combine all enriched/natural detectors and plot an overall efficiency.
    This is more for curiosity
    """
    from statsmodels.stats import proportion
    from scipy.optimize import curve_fit

    # very important parameter
    pctTot = 90
    # pctTot = 95

    print("Using pctTot ==",pctTot)

    # overall hit and efficiency plots (low-E region)
    xPassLo, xPassHi, xpbPass = 0, 50, 1      # "low energy" region
    xTot, hPassEnr = wl.GetHisto([], xPassLo, xPassHi, xpbPass, shift=False)
    xTot, hFailEnr = wl.GetHisto([], xPassLo, xPassHi, xpbPass, shift=False)
    xTot, hTotEnr = wl.GetHisto([], xPassLo, xPassHi, xpbPass, shift=False)
    xTot, hPassNat = wl.GetHisto([], xPassLo, xPassHi, xpbPass, shift=False)
    xTot, hFailNat = wl.GetHisto([], xPassLo, xPassHi, xpbPass, shift=False)
    xTot, hTotNat = wl.GetHisto([], xPassLo, xPassHi, xpbPass, shift=False)

    # weibull fit constraints: energy, (c, loc, scale, amp)
    eFitHi = 30
    fitBnd = ((1,-20,0,0.5),(np.inf,np.inf,np.inf, 0.99)) # eFitHi=30 and these works!

    # load efficiency data
    f = np.load('./data/lat2-eff-data-%d.npz' % pctTot)
    effData = f['arr_0'].item()
    detList = det.allDets
    for i, cpd in enumerate(detList):
        if cpd not in effData.keys():
            continue
        xEff, sloEff, ci_low, ci_upp = effData[cpd][0], effData[cpd][1], effData[cpd][2], effData[cpd][3]
        hPass, hFail, hTot, xELow = effData[cpd][4], effData[cpd][5], effData[cpd][6], effData[cpd][7]

        if det.isEnr(cpd):
            hTotEnr = np.add(hTotEnr, hTot)
            hPassEnr = np.add(hPassEnr, hPass)
            hFailEnr = np.add(hFailEnr, hFail)
        else:
            hTotNat = np.add(hTotNat, hTot)
            hPassNat = np.add(hPassNat, hPass)
            hFailNat = np.add(hFailNat, hFail)

    # === calculate enr/nat efficiency, see above for a more verbose explanation  ===

    fig = plt.figure()

    # enriched efficiency
    nBinEnr = np.sum(hPassEnr[np.where(xELow < 10)])/(10/xpbPass)
    idxP = np.where(hPassEnr > 0)
    sloEffEnr = hPassEnr[idxP] / hTotEnr[idxP]
    xEffEnr = xELow[idxP]
    ciLowEnr, ciUppEnr = proportion.proportion_confint(hPassEnr[idxP], hTotEnr[idxP], alpha=0.1, method='beta')
    idxE = np.where((xEffEnr < xPassHi) & (xEffEnr > 1))
    xEffEnr, sloEffEnr, ciLowEnr, ciUppEnr = xEffEnr[idxE], sloEffEnr[idxE], ciLowEnr[idxE], ciUppEnr[idxE]
    xEffEnr -= xpbPass/2.
    idxF = np.where(xEffEnr <= eFitHi)
    poptEnr,_ = curve_fit(wl.weibull, xEffEnr[idxF], sloEffEnr[idxF], bounds=fitBnd)

    # natural efficiency
    nBinNat = np.sum(hPassNat[np.where(xELow < 10)])/(10/xpbPass)
    idxP = np.where(hPassNat > 0)
    sloEffNat = hPassNat[idxP] / hTotNat[idxP]
    xEffNat = xELow[idxP]
    ciLowNat, ciUppNat = proportion.proportion_confint(hPassNat[idxP], hTotNat[idxP], alpha=0.1, method='beta')
    idxE = np.where((xEffNat < xPassHi) & (xEffNat > 1))
    xEffNat, sloEffNat, ciLowNat, ciUppNat = xEffNat[idxE], sloEffNat[idxE], ciLowNat[idxE], ciUppNat[idxE]
    xEffNat -= xpbPass/2.
    idxF = np.where(xEffNat <= eFitHi)
    poptNat,_ = curve_fit(wl.weibull, xEffNat[idxF], sloEffNat[idxF], bounds=fitBnd)

    # plot overall enr/nat hit spectrum
    plt.plot(xTot, hTotEnr, ls='steps', c='k', label="Enr, Total Hits")
    plt.plot(xTot, hPassEnr, ls='steps', c='b', label="Enr, Pass")
    plt.plot(xTot, hFailEnr, ls='steps', c='r', label="Enr, Fail")
    plt.plot(xTot, hTotNat, ls='steps', c='m', label="Nat, Total Hits")
    plt.plot(xTot, hPassNat, ls='steps', c='g', label="Nat, Pass")
    plt.plot(xTot, hFailNat, ls='steps', c='orange', label="Nat, Fail")

    plt.axvline(1., c='g', lw=1, label='1 kev')
    plt.xlabel("Energy (keV)", ha='right', x=1)
    plt.ylabel("Counts/%.1f keV" % xpbPass, ha='right', y=1)
    plt.xlim(xPassLo, xPassHi)
    plt.legend(loc=1, bbox_to_anchor=(0., 0.5, 1, 0.2))
    plt.tight_layout()
    # plt.show()
    plt.savefig("./plots/lat2-eff%d-totHits.pdf" % pctTot)

    # efficiency plot, with sigma residual

    # renaming key:
    # xEff, sloEff, nBin, ci_low, ci_upp, popt
    # xEffEnr, sloEffEnr, nBinEnr, ciLowEnr, ciUppEnr, poptEnr
    # xEffNat, sloEffNat, nBinNat, ciLowNat, ciUppNat, poptNat

    plt.close()
    # fig = plt.figure(figsize=(8,6))
    # p1 = plt.subplot2grid((3,1), (0,0), rowspan=2)
    # p2 = plt.subplot2grid((3,1), (2,0), sharex=p1)
    fig = plt.figure()
    p1 = plt.subplot(111)
    xFunc = np.arange(xPassLo, xPassHi, 0.1)
    p1.axvline(1, c='k', lw=1)
    # p2.axvline(1, c='k', lw=1)

    p1.plot(xEffEnr, sloEffEnr, '.b', ms=10., label='Enriched Detectors, nBin %.1f' % (nBinEnr))
    p1.errorbar(xEffEnr, sloEffEnr, yerr=[sloEffEnr - ciLowEnr, ciUppEnr - sloEffEnr], color='k', linewidth=0.8, fmt='none')
    p1.plot(xFunc, wl.weibull(xFunc, *poptEnr), 'b-', lw=2, alpha=0.8)
    p1.axvline(np.nan, np.nan, c="w", label='1.0 keV enr eff: %.2f' % wl.weibull(1.,*poptEnr))

    p1.plot(xEffNat, sloEffNat, '.m', ms=10., label='Natural Detectors, nBin %.1f' % (nBinNat))
    p1.errorbar(xEffNat, sloEffNat, yerr=[sloEffNat - ciLowNat, ciUppNat - sloEffNat], color='k', linewidth=0.8, fmt='none')
    p1.plot(xFunc, wl.weibull(xFunc, *poptNat), 'm-', lw=2, alpha=0.8)
    p1.axvline(np.nan, np.nan, c="w", label='1.0 keV nat eff: %.2f' % wl.weibull(1.,*poptNat))

    p1.set_xlim(xPassLo, xPassHi)
    p1.set_ylim(0.2,1)
    p1.set_xlabel("hitE (keV)", ha='right', x=1)
    p1.set_ylabel("Efficiency", ha='right', y=1)
    p1.yaxis.set_label_coords(-0.095, 1.)
    p1.legend(loc=4)

    plt.tight_layout()
    # plt.show()
    plt.savefig("./plots/lat2-eff%d.pdf" % (pctTot))

    # p2.plot(xEff, hResidSig, ".g")
    # p2.annotate('Residual, Fit - Data', xy=(470, 80), xycoords='axes points', size=14, ha='right', va='center', bbox=dict(boxstyle='round', fc='w', alpha=0.75, edgecolor='gray'))
    # p2.axvline(1.,color='b', lw=1.)
    # p2.set_xlim(xPassLo, xPassHi)
    # yLo = -0.4 if np.min(hResidSig) > -0.4 else np.min(hResidSig) * 1.1
    # yHi = 0.4 if np.max(hResidSig) < 0.4 else np.max(hResidSig) * 1.1
    # p2.set_ylim(yLo, yHi)
    # p2.set_ylabel("Residual (Sigma)")
    # p2.set_xlabel("Energy (keV)", ha='right', x=1)
    # p2.set_xticks(np.arange(0,51,5))
    # plt.tight_layout()
    # fig.subplots_adjust(hspace=0.01)
    # plt.setp(p1.get_xticklabels(), visible=False)


def fitSlo_exposure_weighted_eff():

    f = np.load(dsi.latSWDir+'/data/lat-expo-efficiency-all.npz')

    xEff = f['arr_0']
    eMin, eMax, nBins = 0, 50, len(xEff)
    totEnrEff = f['arr_1'].tolist()
    totNatEff = f['arr_2'].tolist()
    enrExp = f['arr_3'].tolist()
    natExp = f['arr_4'].tolist()

    cmap = plt.cm.get_cmap('brg',len(totEnrEff)+1)

    for i, ds in enumerate(totEnrEff):
        plt.plot(xEff, 0.9 * totEnrEff[ds]/np.max(totEnrEff[ds]), c=cmap(i), label="DS-%s" % str(ds))

    plt.xlim(0,15)
    plt.xlabel("Energy (keV)", ha='right', x=1)
    plt.ylabel("Enr. Acceptance", ha='right', y=1)
    plt.yticks(np.arange(0,1.1,0.1))
    plt.legend(loc=4)
    plt.tight_layout()
    plt.show()


def get_ext_pulser_data():
    """ Adapted from ext2.py::getEff
    Just gets data and save into a npz file.
    """
    from ROOT import TChain, GATDataSet
    import glob

    # this is the output
    extData = {} # {run: [pIdx, runTime, extChan, hitE, fSlo]}

    for pIdx in [19,20,21]:
    # for pIdx in [19]:

        extPulserInfo = cal.GetSpecialList()["extPulserInfo"]
        attList = extPulserInfo[pIdx][0] # unused
        extChan = extPulserInfo[pIdx][-1]
        syncChan = wl.getChan(0,10,0) # 672

        runList = cal.GetSpecialRuns("extPulser",pIdx)
        for run in runList:

            # elogs: "20 Hz, 150 second runs"
            gds = GATDataSet(run)
            runTime = gds.GetRunTime() # sec
            # pulseRate = 20 # Hz

            fList = glob.glob(dsi.specialDir+"/lat/latSkimDS0_run%d_*.root" % run)
            tt = TChain("skimTree")
            for f in fList: tt.Add(f)

            tCut = "(channel==%d || channel==%d) && mH==2" % (syncChan, extChan) # enforce correct sync
            n = tt.Draw("trapENFCal:channel:fitSlo",tCut,"goff")
            hitE, chan, fSlo = tt.GetV1(), tt.GetV2(), tt.GetV3()
            hitE = np.asarray([hitE[i] for i in range(n) if chan[i]==extChan])
            fSlo = np.asarray([fSlo[i] for i in range(n) if chan[i]==extChan])

            if len(hitE)==0:
                continue

            extData[run] = [pIdx, runTime, extChan, hitE, fSlo]

            tt.Reset()

    # save output
    # np.savez("./data/lat-extPulser.npz",extData)


def plot_ext_pulser():
    """ The ext pulser data doesn't have the same centroid as the physics data
    since it wasn't tuned quite right.  So we find the centroid of a higher-E set for each channel
    and plot the other ones relative to that. """

    ds, cIdx, bIdx, sIdx = 0, 33, 75, 0 # runs 6887-6963, closest to this one
    # calDB = db.TinyDB('./calDB.json')
    # pars = db.Query()
    # fsD = dsi.getDBRecord("fitSlo_%s_idx%d_m2s238" % ("ds0_m1", cIdx), False, calDB, pars)
    # thD = dsi.getDBRecord("thresh_ds%d_bkg%d_sub%d" % (ds, bIdx, sIdx), False, calDB, pars)

    f = np.load("./data/lat-extPulser.npz")
    extData = f['arr_0'].item()  # {run: [pIdx, runTime, extChan, hitE, fSlo]}

    # get centroids
    # for run in extData:
    #     ch = extData[run][2]
    #     muE = np.mean(extData[run][3])
    #     stdE = np.std(extData[run][3])
    #     muFS = np.mean(extData[run][4])
    #     stdFS = np.std(extData[run][4])
    #     print("run %d  ch %d  E %.2f pm %.2f  FS %.2f pm %.2f" % (run, ch, muE, stdE, muFS, stdFS))
    # run 7236  ch 624  E 54.78 pm 0.14  FS 74.80 pm 1.41
    # run 7249  ch 688  E 46.83 pm 0.11  FS 67.14 pm 1.81
    # run 7220  ch 674  E 71.53 pm 1.30  FS 67.56 pm 95.30
    # runMap = {7236:624, 7249:688, 7220:674}

    # cent = {}
    # for run in extData:
    #     if run not in runMap: continue
    #     ch = extData[run][2]
    #     fLo, fHi, fpb = 50, 100, 0.5
    #     x, hist = wl.GetHisto(extData[run][4], fLo, fHi, fpb)
    #     fMax = x[np.argmax(hist)]
    #     cent[ch] = fMax
    #     # plt.plot(x, hist, ls='steps')
    #     # plt.axvline(fMax, c='r')
    #     # plt.show()

    # this is the result of the above block
    centMap = {624: 74.75, 688: 67.25, 674: 65.75}

    fig = plt.figure(figsize=(8,6))
    p1 = plt.subplot(211)
    p2 = plt.subplot(212)

    # hitE, fSlo = [], []
    cols = {624:'r', 688:'g', 674:'b'}
    for run in extData:
        ch = extData[run][2]
        hitE = extData[run][3]
        # fSlo = extData[run][4] # unshifted
        fSlo = [fs - centMap[ch] for fs in extData[run][4]] # shifted
        p1.plot(hitE, fSlo, '.', c=cols[ch], ms=0.5, alpha=0.7)

        fLo, fHi, fpb = -50, 200, 2
        x, hist = wl.GetHisto(fSlo, fLo, fHi, fpb)
        fMax = x[np.argmax(hist)]
        muE = np.mean(hitE)
        p2.plot(muE, fMax, ".", c=cols[ch], ms=10)

    for ch in cols:
        cpd = det.getChanCPD(ds, ch)
        p1.plot(np.nan, np.nan, '.', c=cols[ch], label="C%sP%sD%s" % (cpd[0],cpd[1],cpd[2]))
        p2.plot(np.nan, np.nan, '.', c=cols[ch], label="C%sP%sD%s" % (cpd[0],cpd[1],cpd[2]))

    p1.set_ylim(-100, 150) # shifted
    # p1.set_ylim(0, 200) # unshifted

    p1.set_xlim(0, 20)
    p2.set_xlim(0, 20)
    p2.legend()
    p2.set_xlabel("Energy (keV)", ha='right', x=1)
    p2.set_ylabel("fitSlo Centroid", ha='right', y=1)
    p1.set_ylabel("fitSlo", ha='right', y=1)

    plt.tight_layout()
    # plt.show()
    plt.savefig("./plots/lat-extPulser-centroid.pdf")


def ext_pulser_width():

    f = np.load("../data/lat-extPulser.npz")
    extData = f['arr_0'].item()  # {run: [pIdx, runTime, extChan, hitE, fSlo]}

    extInfo = {624:[7236, 74.75, 'r'], 688:[7249, 67.25, 'g'], 674:[7220, 65.75, 'b']}

    def xGaussPDF(x,k,loc,scale,amp):
        """ amp=overall multip factor, loc=mu, sc=sigma, k=tau """
        from scipy.stats import exponnorm
        return amp * exponnorm.pdf(x,k,loc,scale)

    def xGaussCDF(x,k,loc,scale,amp):
        from scipy.stats import exponnorm
        return exponnorm.cdf(x,k,loc,scale)

    fsMax, fsLo, fsHi, fsE, fsR = [], [], [], [], []

    xgFits = {}

    for i, run in enumerate(extData):

        ch = extData[run][2]
        cpd = det.getChanCPD(0, ch)

        # if ch != 674: continue
        # if i != 14: continue
        if run in [7233]: continue

        hitE = extData[run][3]
        fSlo = extData[run][4]
        idx = np.where(np.isfinite(hitE))
        hitE, fSlo = hitE[idx], fSlo[idx]

        muE = np.average(hitE)
        sdE = np.std(hitE)
        if muE < 1.: continue
        if muE > 100: continue

        runTime = extData[run][1]/1e9 # elogs: 20 Hz, 150 sec runs
        pulseRate = 20 # Hz
        nExp = int(runTime * pulseRate)
        nTot = len(hitE)
        tEff = nTot / nExp

        # fSlo = extData[run][4] # unshifted
        fSlo = [fs - extInfo[ch][1] for fs in extData[run][4]] # shifted

        fLo, fHi = np.percentile(fSlo,1) * 1.2, np.percentile(fSlo,97) * 1.2
        if fHi > 50: fHi = 50

        nb = 100
        fpb = (fHi-fLo)/nb

        x, h = wl.GetHisto(fSlo, fLo, fHi, fpb, shift=False)
        fMax = x[np.argmax(h)]
        pct = []
        for p in [10, 90]:
            tmp = np.cumsum(h)/np.sum(h)*100
            idx = np.where(tmp > p)
            pct.append(x[idx][0])
        wid = pct[1]-pct[0]

        fsMax.append(fMax)
        fsLo.append(pct[0])
        fsHi.append(pct[1])
        fsE.append(muE)
        fsR.append(run)

        tau, mu, sig, amp = 10, fMax, 10, 10000
        np.seterr(invalid='ignore', over='ignore')
        popt,_ = curve_fit(xGaussPDF, x, h, p0=(tau, mu, sig, amp)) # tau, mu, sig, amp
        np.seterr(invalid='warn', over='warn')
        xgFits[run] = popt

        # print("%d  %d  %d  lo %.2f  hi %.2f  fpb %.2f  E %-5.1f  rt %.1f  %d/%d (%.3f)  FS  10%% %-5.1f  max %-5.1f  90%% %-5.1f  W %.1f" % (i, run, ch, fLo, fHi, fpb, muE, runTime, nTot, nExp, tEff, pct[0], fMax, pct[1], wid))

        # plt.plot(x, h, ls='steps-mid', c=extInfo[ch][2], label="C%sP%sD%s, E %.1f  Max %.1f  Wid %.1f" % \
        #     (cpd[0],cpd[1],cpd[2],muE, fMax,wid))
        # xFunc = np.arange(fLo, fHi, 0.01)
        # tau, mu, sig, amp = popt
        # xgFit = xGaussPDF(xFunc, *popt)
        # xgMax = xFunc[np.argmax(xgFit)]
        # plt.plot(xFunc, xgFit, '-b', label = "xGaus, tau %.1f  mu %.1f  sig %.1f  amp %.1f" % (tau, mu, sig, amp))
        # # get CDF
        # # xgInt = xGaussCDF(xFunc, *popt)
        # # distMax = np.amax(xgFit)
        # # plt.plot(xFunc, xgInt, '-k', label = "xGauss CDF")
        # # plt.axvline(xgMax, c='m', label='xg max %.1f' % xgMax)
        # # plt.axvline(fMax, c='k')
        # plt.axvline(pct[0], c='b')
        # plt.axvline(pct[1], c='g')
        # plt.xlabel("fitSlo (shifted)", ha='right', x=1)
        # plt.legend(loc=1, fontsize=10)
        # plt.tight_layout()
        # plt.show()

        # return

    # ======== plot the fast pulse envelope ========

    fsMax, fsLo, fsHi, fsE, fsR = np.asarray(fsMax), np.asarray(fsLo), np.asarray(fsHi), np.asarray(fsE). np.asarray(fsR)
    idx = np.argsort(fsE)
    fsMax, fsLo, fsHi, fsE = fsMax[idx], fsLo[idx], fsHi[idx], fsE[idx]
    wid = fsHi[-1] - fsLo[-1]
    fsWid = (fsHi-fsLo)/wid

    # for i in range(len(fsE)):
        # print("E %.1f  fMax %.1f  fWid %.1f" % (fsE[i], fsMax[i], fsWid[i]))

    plt.errorbar(fsE, fsMax, yerr=[fsMax-fsLo, fsHi-fsMax], ms=7, lw=3, c='k', fmt='o')
    # plt.errorbar(fsE, fsMax, yerr=fsWid, ms=1, lw=2, c='r', fmt='o')

    def exp1(x, a, b, t): return a * np.exp(x / t) + b
    def exp2(x, a, b, t): return a * (1 - np.exp(x / t)) + b

    poptUP,_ = curve_fit(exp1, fsE, fsHi, p0=(90, 3, -3))
    poptCT,_ = curve_fit(exp2, fsE, fsMax, p0=(100, -100, -3))
    poptLO,_ = curve_fit(exp2, fsE, fsLo, p0=(100, -100, -3))

    xFunc = np.arange(1, 20, 0.01)
    plt.plot(xFunc, exp1(xFunc,*poptUP), "-r")
    plt.plot(xFunc, exp2(xFunc,*poptCT), "-g")
    plt.plot(xFunc, exp2(xFunc,*poptLO), "-r")

    plt.xlim(1, 2)
    plt.xlabel("Energy (keV)", ha='right', x=1)
    plt.ylabel("fitSlo (shifted)", ha='right', y=1)
    plt.tight_layout()
    plt.show()


if __name__=="__main__":
    main()